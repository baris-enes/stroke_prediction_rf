#  Stroke Prediction mit Machine Learning

##  ProjektÃ¼berblick

Ziel dieses Projekts ist die Entwicklung eines Vorhersagemodells zur EinschÃ¤tzung des Schlaganfallrisikos auf Basis medizinischer und demografischer Patientendaten. Der zugrunde liegende Datensatz umfasst Ã¼ber 5.000 EintrÃ¤ge mit Merkmalen wie Alter, Blutzucker, BMI, Beruf und Rauchverhalten.

Da SchlaganfÃ¤lle nur bei etwa 5â€¯% der FÃ¤lle auftreten, besteht ein starkes Klassenungleichgewicht. Deshalb liegt der Schwerpunkt auf dem F1-Score der positiven Klasse (stroke = 1), um SensitivitÃ¤t und PrÃ¤zision gleichermaÃŸen zu bewerten.

Im Rahmen dieses Projekts wurden verschiedene Machine-Learning-Algorithmen untersucht â€“ darunter SVM, Logistische Regression, KNN und Naive Bayes.
Der Fokus dieses GitHub-Repositories liegt auf dem `Random Forest Classifier`, da dieser in meiner Analyse das beste Gleichgewicht zwischen Recall und PrÃ¤zision erreicht hat.

##  Datensatz

- **Beobachtungen:** 5.110 Patientendaten
- **Features:** Alter, Geschlecht, Hypertonie, Herzkrankheiten, Familienstand, Beruf, Wohnort, Glukose, BMI, Raucherstatus
- **Ziel:** BinÃ¤re Variable `stroke` (0 = kein Schlaganfall, 1 = Schlaganfall)


##  ModellÃ¼bersicht & Performancevergleich

| Modell                  | Accuracy | F1-Score (Positiv) | Besonderheiten |
|------------------------|----------|--------------------|----------------|
| ðŸ”µ Random Forest        | 88 %     | **0.29**           | Bestes Modell (mit Gewichtung), gute Balance |
| ðŸŸ  Support Vector Classifier (SVC) | 85 %     | 0.26               | Polynom-Kernel, Recall hoch |
| ðŸŸ¢ Decision Tree        | 86 %     | 0.19               | Inkl. SMOTE, aber viele False Positives |
| ðŸ”´ K-Nearest Neighbors  | 83 %     | 0.13               | Hoher Bias, Recall schlecht |
| âšª Naive Bayes          | 82 %     | 0.14               | Extrem hoher Recall, kaum PrÃ¤zision |
| ðŸŸ¡ Logistische Regression | 84 %   | 0.22 â€“ 0.25        | Gute Basis, stabil auch mit wenigen Features |


##  Bewertungskriterien

- **F1-Score Klasse 1** als wichtigste Metrik  
- Train/Test-Split: 80/20 (stratifiziert)  
- Kreuzvalidierung: 5-fach  
- Klassengewichtungen vs. SMOTE getestet


##  Lessons Learned

- Gewichtung der Klassen stabiler als SMOTE
- GridSearch verbessert Recall signifikant
- Dropping von Daten (z.â€¯B. Junge Patienten) kann Recall senken
- F1-Score bietet bessere Aussagekraft als Accuracy bei Imbalance


##  Projektstruktur

```
.
â”œâ”€â”€ healthcare_dataset_random_forest_.ipynb
â”œâ”€â”€ healthcare-dataset-stroke-data.csv
â”œâ”€â”€ df_final.csv
â”œâ”€â”€ requirements.txt
```


##  AusfÃ¼hrung

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

Dann im Notebook starten:
```bash
jupyter notebook
```
â†’ Ã–ffne `healthcare_dataset_random_forest_.ipynb`


##  Hinweis

Die Daten stammen aus einem Ã¶ffentlich zugÃ¤nglichen Kaggle-Datensatz. Das Modell dient **ausschlieÃŸlich zu Lernzwecken**.

